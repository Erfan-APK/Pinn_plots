import torch
from matplotlib.path import Path
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
from matplotlib.collections import LineCollection
import time
from scipy.interpolate import griddata
import os
from datetime import datetime

# Set seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)

# Enforce CUDA-only operation
assert torch.cuda.is_available(), "CUDA required"
device = torch.device("cuda")
torch.set_default_dtype(torch.float32)
torch.backends.cudnn.benchmark = True
print(f"Using device: {device}")
print(f"GPU: {torch.cuda.get_device_name()}")
print(f"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")



class NACA0012:
    """NACA 0012 airfoil geometry generator"""

    def __init__(self, chord=1.0, n_points=200):
        self.chord = chord
        self.n_points = n_points
        self._x_airfoil = None
        self._y_airfoil = None
        self._generate_coordinates()

    def _generate_coordinates(self):
        """Generate NACA 0012 airfoil coordinates"""

        # Thickness distribution for NACA 0012
        def thickness(x):
            return 0.12 / 0.2 * (
                    0.2969 * np.sqrt(x) -
                    0.1260 * x -
                    0.3516 * x ** 2 +
                    0.2843 * x ** 3 -
                    0.1015 * x ** 4
            )

        # Generate x coordinates (clustered near leading/trailing edges)
        beta = np.linspace(0, np.pi, self.n_points // 2)
        x = 0.5 * (1 - np.cos(beta)) * self.chord

        # Calculate thickness
        t = thickness(x / self.chord) * self.chord

        # Upper and lower surfaces
        x_upper = x
        y_upper = t
        x_lower = x
        y_lower = -t

        # Combine (clockwise from trailing edge)
        self._x_airfoil = np.concatenate([x_upper[::-1], x_lower[1:]])
        self._y_airfoil = np.concatenate([y_upper[::-1], y_lower[1:]])

    def get_coordinates(self):
        return self._x_airfoil, self._y_airfoil

    def is_inside_airfoil_vectorized(self, x, y):
        """Vectorized point-in-polygon test using matplotlib Path"""
        from matplotlib.path import Path

        # Create path from airfoil coordinates
        airfoil_path = Path(np.vstack([self._x_airfoil, self._y_airfoil]).T)

        # Flatten inputs
        original_shape = x.shape
        points = np.vstack([x.flatten(), y.flatten()]).T

        # Check if points are inside
        inside = airfoil_path.contains_points(points)

        return inside.reshape(original_shape)


class PINN(nn.Module):
    """Optimized Physics-Informed Neural Network"""

    def __init__(self, input_dim=2, hidden_dim=128, output_dim=3, num_layers=6):
        super(PINN, self).__init__()

        # Network layers with batch normalization for stability
        layers = []
        layers.append(nn.Linear(input_dim, hidden_dim))
        layers.append(nn.BatchNorm1d(hidden_dim))

        for _ in range(num_layers - 2):
            layers.append(nn.Linear(hidden_dim, hidden_dim))
            layers.append(nn.BatchNorm1d(hidden_dim))

        layers.append(nn.Linear(hidden_dim, output_dim))

        self.layers = nn.ModuleList(layers)
        self.activation = nn.Tanh()

        # Initialize weights
        self._init_weights()

    def _init_weights(self):
        """Xavier initialization for better convergence"""
        for layer in self.layers:
            if isinstance(layer, nn.Linear):
                nn.init.xavier_normal_(layer.weight)
                nn.init.zeros_(layer.bias)

    def forward(self, xy):
        """Forward pass with residual connections"""
        x = xy

        for i in range(0, len(self.layers) - 1, 2):
            residual = x if x.shape[-1] == self.layers[i].out_features else None

            x = self.layers[i](x)
            if i + 1 < len(self.layers) - 1:  # Skip batch norm for output layer
                x = self.layers[i + 1](x)
            x = self.activation(x)

            # Add residual connection for deeper layers
            if residual is not None and i > 0:
                x = x + residual

        # Output layer
        x = self.layers[-1](x)
        return x


class NavierStokesPINN:
    """Optimized PINN solver for Navier-Stokes equations"""

    def __init__(self, Re=200, domain_bounds=(-5, 15, -5, 5)):
        self.Re = Re
        self.nu = 1.0 / Re
        self.domain_bounds = domain_bounds

        # Input scaling parameters for better convergence
        self.x_mean = (domain_bounds[0] + domain_bounds[1]) / 2.0
        self.x_scale = (domain_bounds[1] - domain_bounds[0]) / 2.0
        self.y_mean = (domain_bounds[2] + domain_bounds[3]) / 2.0
        self.y_scale = (domain_bounds[3] - domain_bounds[2]) / 2.0

        # Initialize airfoil and network
        self.airfoil = NACA0012(chord=1.0)
        self.net = PINN(input_dim=2, hidden_dim=128, output_dim=3, num_layers=6).to(device)

        # Optimized training parameters
        self.optimizer = torch.optim.AdamW(self.net.parameters(), lr=2e-3, weight_decay=1e-6)
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=20000, eta_min=1e-6)

        # Balanced loss weights
        # self.w_pde = 1.0
        # self.w_bc_inlet = 50.0
        # self.w_bc_outlet = 10.0
        # self.w_bc_wall = 100.0

        # Adjusted loss weights for better convergence
        self.w_pde = 1.0
        self.w_bc_inlet = 10.0  # reduced from 50
        self.w_bc_outlet = 5.0  # reduced from 10
        self.w_bc_wall = 20.0  # reduced from 100

        # Pre-generate and cache training points
        self._cache_training_points()

    def _scale_torch(self, x, y):
        """Scale inputs to [-1, 1] for better network training"""
        return (x - self.x_mean) / self.x_scale, (y - self.y_mean) / self.y_scale

    def _cache_training_points(self):
        """Pre-generate training points for efficiency"""
        print("Generating training point cache...")

        # Large batch of interior points
        n_interior = 20000
        n_boundary = 4000

        x_min, x_max, y_min, y_max = self.domain_bounds


        # Interior points (reject airfoil interior) - ensure float32
        x_int = torch.rand(n_interior * 2, dtype=torch.float32, device=device) * (x_max - x_min) + x_min
        y_int = torch.rand(n_interior * 2, dtype=torch.float32, device=device) * (y_max - y_min) + y_min

        # Remove points inside airfoil
        # Remove points inside airfoil using matplotlib's robust method
        x_np = x_int.cpu().numpy()
        y_np = y_int.cpu().numpy()

        # Create airfoil path for robust point-in-polygon test
        x_af, y_af = self.airfoil.get_coordinates()
        airfoil_path = Path(np.vstack([x_af, y_af]).T)

        # Check which points are inside
        points = np.column_stack([x_np, y_np])
        inside_mask = airfoil_path.contains_points(points)

        valid_mask = ~torch.tensor(inside_mask, device=device)
        self.x_interior = x_int[valid_mask][:n_interior].contiguous()
        self.y_interior = y_int[valid_mask][:n_interior].contiguous()

        # Boundary points
        n_per_bc = n_boundary // 5

        # Inlet
        # Inlet - ensure float32 and contiguous
        self.x_inlet = torch.full((n_per_bc,), x_min, dtype=torch.float32, device=device).contiguous()
        self.y_inlet = (torch.rand(n_per_bc, dtype=torch.float32, device=device) * (y_max - y_min) + y_min).contiguous()

        # Outlet - ensure float32 and contiguous
        self.x_outlet = torch.full((n_per_bc,), x_max, dtype=torch.float32, device=device).contiguous()
        self.y_outlet = (
                    torch.rand(n_per_bc, dtype=torch.float32, device=device) * (y_max - y_min) + y_min).contiguous()

        # Walls - ensure float32 and contiguous
        self.x_wall_top = (
                    torch.rand(n_per_bc, dtype=torch.float32, device=device) * (x_max - x_min) + x_min).contiguous()
        self.y_wall_top = torch.full((n_per_bc,), y_max, dtype=torch.float32, device=device).contiguous()

        self.x_wall_bottom = (
                    torch.rand(n_per_bc, dtype=torch.float32, device=device) * (x_max - x_min) + x_min).contiguous()
        self.y_wall_bottom = torch.full((n_per_bc,), y_min, dtype=torch.float32, device=device).contiguous()


        # Airfoil surface
        x_af, y_af = self.airfoil.get_coordinates()
        indices = torch.randint(0, len(x_af), (n_per_bc,), device=device)
        # Ensure float32 (not float64) so inputs dtype matches model/autocast expectations
        self.x_airfoil = torch.tensor(x_af, dtype=torch.float32, device=device)[indices]
        self.y_airfoil = torch.tensor(y_af, dtype=torch.float32, device=device)[indices]

        print(f"Cached {len(self.x_interior)} interior points")
        print(f"Cached {n_per_bc} points per boundary")

    def compute_pde_loss(self):
        """Compute PDE loss with automatic differentiation"""
        # Randomly sample from cached points for each epoch
        batch_size = 8192
        indices = torch.randperm(len(self.x_interior), device=device)[:batch_size]

        x = self.x_interior[indices].requires_grad_(True)
        y = self.y_interior[indices].requires_grad_(True)

        # Forward pass with scaled inputs
        x_scaled, y_scaled = self._scale_torch(x, y)
        xy = torch.stack([x_scaled, y_scaled], dim=1)
        output = self.net(xy)
        u_raw, v_raw, p_raw = output[:, 0], output[:, 1], output[:, 2]

        # Map network outputs to physical ranges
        u = 1.0 + 0.5 * torch.tanh(u_raw)  # maps to roughly (0.5, 1.5) centered at 1
        v = 0.3 * torch.tanh(v_raw)  # small v-range, centered at 0
        p = p_raw  # keep pressure raw for now

        # First derivatives
        u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]
        u_y = torch.autograd.grad(u.sum(), y, create_graph=True)[0]
        v_x = torch.autograd.grad(v.sum(), x, create_graph=True)[0]
        v_y = torch.autograd.grad(v.sum(), y, create_graph=True)[0]
        p_x = torch.autograd.grad(p.sum(), x, create_graph=True)[0]
        p_y = torch.autograd.grad(p.sum(), y, create_graph=True)[0]

        # Second derivatives
        u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0]
        u_yy = torch.autograd.grad(u_y.sum(), y, create_graph=True)[0]
        v_xx = torch.autograd.grad(v_x.sum(), x, create_graph=True)[0]
        v_yy = torch.autograd.grad(v_y.sum(), y, create_graph=True)[0]

        # PDE residuals
        continuity = u_x + v_y
        momentum_x = u * u_x + v * u_y + p_x - self.nu * (u_xx + u_yy)
        momentum_y = u * v_x + v * v_y + p_y - self.nu * (v_xx + v_yy)

        return torch.mean(continuity ** 2 + momentum_x ** 2 + momentum_y ** 2)

    def compute_bc_loss(self):
        """Compute boundary condition losses"""
        total_loss = 0.0

        # Inlet: u = 1, v = 0
        x_inlet_scaled, y_inlet_scaled = self._scale_torch(self.x_inlet, self.y_inlet)
        xy_inlet = torch.stack([x_inlet_scaled, y_inlet_scaled], dim=1)
        output_inlet = self.net(xy_inlet)
        u_raw, v_raw = output_inlet[:, 0], output_inlet[:, 1]

        # Apply scaling
        u_inlet = 1.0 + 0.5 * torch.tanh(u_raw)
        v_inlet = 0.3 * torch.tanh(v_raw)

        inlet_loss = torch.mean((u_inlet - 1.0) ** 2 + v_inlet ** 2)
        total_loss += self.w_bc_inlet * inlet_loss

        # Outlet: p = 0 (simplified)
        x_outlet_scaled, y_outlet_scaled = self._scale_torch(self.x_outlet, self.y_outlet)
        xy_outlet = torch.stack([x_outlet_scaled, y_outlet_scaled], dim=1)
        output_outlet = self.net(xy_outlet)
        p_raw = output_outlet[:, 2]

        # Pressure stays raw (or you can add scaling if needed)
        p_outlet = p_raw

        outlet_loss = torch.mean(p_outlet ** 2)
        total_loss += self.w_bc_outlet * outlet_loss

        # Walls: no-slip
        for x_wall, y_wall in [(self.x_wall_top, self.y_wall_top),
                               (self.x_wall_bottom, self.y_wall_bottom),
                               (self.x_airfoil, self.y_airfoil)]:
            # Scale the wall coordinates
            x_wall_scaled, y_wall_scaled = self._scale_torch(x_wall, y_wall)
            xy_wall = torch.stack([x_wall_scaled, y_wall_scaled], dim=1)
            output_wall = self.net(xy_wall)
            u_raw, v_raw = output_wall[:, 0], output_wall[:, 1]

            # For walls, use different scaling that can reach zero
            u_wall = torch.sigmoid(u_raw)  # maps to (0, 1), can reach 0
            v_wall = 0.3 * torch.tanh(v_raw)

            wall_loss = torch.mean(u_wall ** 2 + v_wall ** 2)
            total_loss += self.w_bc_wall * wall_loss

        return total_loss

    def train(self, epochs=20000, print_freq=500):
        """Optimized training loop"""
        print("Starting optimized PINN training...")

        self.net.train()
        train_start = time.time()
        loss_history = []

        # Enable mixed precision for RTX 3080
        scaler = torch.cuda.amp.GradScaler()

        for epoch in range(epochs):
            self.optimizer.zero_grad()

            # Use automatic mixed precision for speed
            with torch.amp.autocast(device_type='cuda'):
                pde_loss = self.compute_pde_loss()
                bc_loss = self.compute_bc_loss()
                total_loss = self.w_pde * pde_loss + bc_loss

            with torch.no_grad():
                xi, yi = self._scale_torch(self.x_inlet, self.y_inlet)
                out_in = self.net(torch.stack([xi, yi], dim=1))

                # Apply scaling to see actual predicted values
                u_raw = out_in[:, 0]
                v_raw = out_in[:, 1]
                u_scaled = 1.0 + 0.5 * torch.tanh(u_raw)
                v_scaled = 0.3 * torch.tanh(v_raw)

                print(f"  debug inlet u mean {u_scaled.mean().item():.4f}, std {u_scaled.std().item():.4f}")
                print(f"  debug inlet v mean {v_scaled.mean().item():.4f}, std {v_scaled.std().item():.4f}")
                print(f"  debug inlet p mean {out_in[:, 2].mean().item():.4f}, std {out_in[:, 2].std().item():.4f}")

            # Backward pass with gradient scaling
            scaler.scale(total_loss).backward()

            # Gradient clipping for stability
            scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=1.0)

            scaler.step(self.optimizer)
            scaler.update()
            self.scheduler.step()

            loss_history.append(total_loss.item())

            if epoch % print_freq == 0:
                elapsed = time.time() - train_start
                gpu_memory = torch.cuda.memory_allocated() / 1e9
                print(f"Epoch {epoch:5d}/{epochs} | Loss: {total_loss.item():.2e} | "
                      f"PDE: {pde_loss.item():.2e} | BC: {bc_loss.item():.2e} | "
                      f"Time: {elapsed:.1f}s | GPU: {gpu_memory:.1f}GB")

                # Force GPU utilization update
                torch.cuda.synchronize()

            # Save checkpoint every 5000 epochs (INSIDE THE LOOP!)
            if epoch % 5000 == 0 and epoch > 0:
                checkpoint = {
                    'epoch': epoch,
                    'model_state': self.net.state_dict(),
                    'optimizer_state': self.optimizer.state_dict(),
                    'scheduler_state': self.scheduler.state_dict(),
                    'loss': total_loss.item()
                }
                torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')
                print(f"  → Checkpoint saved")

        # AFTER LOOP ENDS:
        train_time = time.time() - train_start
        print(f"\nTraining completed in {train_time:.1f} seconds")

        return loss_history, train_time

    def predict_field_batch(self, X, Y, mask, batch_size=16384):
        """Batched field prediction for memory efficiency"""
        print("Computing flow field...")

        self.net.eval()

        # Flatten and filter valid points
        x_flat = X.flatten()
        y_flat = Y.flatten()
        mask_flat = mask.flatten()

        valid_indices = ~mask_flat
        x_valid = x_flat[valid_indices]
        y_valid = y_flat[valid_indices]

        # Initialize output arrays
        u_valid = np.zeros_like(x_valid)
        v_valid = np.zeros_like(x_valid)
        p_valid = np.zeros_like(x_valid)

        # Process in batches
        n_batches = (len(x_valid) + batch_size - 1) // batch_size

        with torch.no_grad():
            for i in range(n_batches):
                start_idx = i * batch_size
                end_idx = min((i + 1) * batch_size, len(x_valid))

                x_batch = torch.tensor(x_valid[start_idx:end_idx], dtype=torch.float32, device=device)
                y_batch = torch.tensor(y_valid[start_idx:end_idx], dtype=torch.float32, device=device)

                x_scaled, y_scaled = self._scale_torch(x_batch, y_batch)
                xy_batch = torch.stack([x_scaled, y_scaled], dim=1)
                output_batch = self.net(xy_batch)
                u_raw = output_batch[:, 0]
                v_raw = output_batch[:, 1]
                p_raw = output_batch[:, 2]

                # Apply same scaling as in training
                u_scaled = 1.0 + 0.5 * torch.tanh(u_raw)
                v_scaled = 0.3 * torch.tanh(v_raw)
                p_scaled = p_raw  # keep pressure raw

                u_valid[start_idx:end_idx] = u_scaled.cpu().numpy()
                v_valid[start_idx:end_idx] = v_scaled.cpu().numpy()
                p_valid[start_idx:end_idx] = p_scaled.cpu().numpy()

        # Reconstruct full fields
        u_full = np.full_like(x_flat, np.nan)
        v_full = np.full_like(x_flat, np.nan)
        p_full = np.full_like(x_flat, np.nan)

        u_full[valid_indices] = u_valid
        v_full[valid_indices] = v_valid
        p_full[valid_indices] = p_valid

        return u_full.reshape(X.shape), v_full.reshape(X.shape), p_full.reshape(X.shape)

    def compute_forces_fast(self):
        """Fast force computation"""
        print("Computing force coefficients...")

        # Get airfoil surface points
        x_af, y_af = self.airfoil.get_coordinates()
        n_points = len(x_af)

        # Predict pressure on surface
        # Predict pressure on surface
        x_tensor = torch.tensor(x_af, dtype=torch.float32, device=device)
        y_tensor = torch.tensor(y_af, dtype=torch.float32, device=device)

        with torch.no_grad():
            # Scale inputs before network evaluation
            x_scaled, y_scaled = self._scale_torch(x_tensor, y_tensor)
            xy_surf = torch.stack([x_scaled, y_scaled], dim=1)
            output_surf = self.net(xy_surf)
            p_raw = output_surf[:, 2]

            # Apply same scaling as in training (if you scaled pressure)
            p_scaled = p_raw  # or apply scaling if you defined one
            p_surf = p_scaled.cpu().numpy()

        # Compute surface normals
        # Compute surface normals and arc length
        dx = np.gradient(x_af)
        dy = np.gradient(y_af)
        ds = np.sqrt(dx ** 2 + dy ** 2) + 1e-12  # arc length element with small epsilon

        # Tangent and outward normal
        tx = dx / ds
        ty = dy / ds
        nx = ty  # outward normal (rotate tangent 90 degrees)
        ny = -tx

        # Pressure forces (integrate along arc length, not x)
        Fp_x = -np.sum(p_surf * nx * ds)  # Use sum for ds integration
        Fp_y = -np.sum(p_surf * ny * ds)

        # Simplified viscous force estimate
        Fv_x = 0.02  # Approximate viscous drag for Re=200
        Fv_y = 0.0  # No viscous lift at 0 AoA

        # Force coefficients (normalized by 0.5*rho*U^2*c with rho=1, U=1, c=1)
        CD_pressure = 2 * Fp_x
        CD_viscous = 2 * Fv_x
        CL_pressure = 2 * Fp_y
        CL_viscous = 2 * Fv_y

        return {
            'CD_pressure': CD_pressure,
            'CD_viscous': CD_viscous,
            'CD_total': CD_pressure + CD_viscous,
            'CL_pressure': CL_pressure,
            'CL_viscous': CL_viscous,
            'CL_total': CL_pressure + CL_viscous
        }

    def create_visualizations(self, X, Y, U, V, P, mask, forces, save_dir="results"):
        """Create all required visualizations efficiently"""
        os.makedirs(save_dir, exist_ok=True)

        x_af, y_af = self.airfoil.get_coordinates()

        # 1. Velocity magnitude
        print("Creating velocity magnitude plot...")
        plt.figure(figsize=(15, 8))
        speed = np.sqrt(U ** 2 + V ** 2)
        speed[mask] = np.nan

        levels = np.linspace(0, 1.5, 21)
        cs = plt.contourf(X, Y, speed, levels=levels, cmap='viridis', extend='max')
        plt.colorbar(cs, label='Velocity Magnitude')
        plt.fill(x_af, y_af, 'white', edgecolor='black', linewidth=2)
        plt.title('Velocity Magnitude')
        plt.xlabel('x/c')
        plt.ylabel('y/c')
        plt.axis('equal')
        plt.xlim(-2, 8)
        plt.ylim(-3, 3)
        plt.tight_layout()
        plt.savefig(f"{save_dir}/velocity_magnitude.png", dpi=200, bbox_inches='tight')
        plt.close()

        # 2. Pressure contours
        print("Creating pressure contour plot...")
        plt.figure(figsize=(15, 8))
        P_plot = P.copy()
        P_plot[mask] = np.nan

        levels_p = np.linspace(-0.8, 0.8, 21)
        cs = plt.contourf(X, Y, P_plot, levels=levels_p, cmap='RdBu_r', extend='both')
        plt.colorbar(cs, label='Pressure')
        plt.fill(x_af, y_af, 'white', edgecolor='black', linewidth=2)
        plt.title('Pressure Field')
        plt.xlabel('x/c')
        plt.ylabel('y/c')
        plt.axis('equal')
        plt.xlim(-2, 8)
        plt.ylim(-3, 3)
        plt.tight_layout()
        plt.savefig(f"{save_dir}/pressure_contours.png", dpi=200, bbox_inches='tight')
        plt.close()

        # 3. Streamlines
        print("Creating streamlines...")
        plt.figure(figsize=(15, 8))

        U_stream = U.copy()
        V_stream = V.copy()
        U_stream[mask] = 0
        V_stream[mask] = 0

        y_starts = np.linspace(-4, 4, 15)
        x_starts = np.full_like(y_starts, -4)

        plt.streamplot(X, Y, U_stream, V_stream,
                       start_points=np.column_stack([x_starts, y_starts]),
                       density=1.5, linewidth=1.2, color='darkblue', arrowsize=1.5)

        speed = np.sqrt(U ** 2 + V ** 2)
        speed[mask] = np.nan
        cs = plt.contourf(X, Y, speed, levels=15, alpha=0.7, cmap='plasma')
        plt.colorbar(cs, label='Velocity Magnitude')

        plt.fill(x_af, y_af, 'white', edgecolor='black', linewidth=2)
        plt.title('Streamlines')
        plt.xlabel('x/c')
        plt.ylabel('y/c')
        plt.axis('equal')
        plt.xlim(-2, 8)
        plt.ylim(-3, 3)
        plt.tight_layout()
        plt.savefig(f"{save_dir}/streamlines.png", dpi=200, bbox_inches='tight')
        plt.close()

        # 4. Surface pressure
        print("Creating surface pressure plot...")
        x_surf, y_surf = self.airfoil.get_coordinates()

        x_tensor = torch.tensor(x_surf, dtype=torch.float32, device=device)
        y_tensor = torch.tensor(y_surf, dtype=torch.float32, device=device)

        with torch.no_grad():
            x_scaled, y_scaled = self._scale_torch(x_tensor, y_tensor)
            xy_surf = torch.stack([x_scaled, y_scaled], dim=1)
            output = self.net(xy_surf)
            p_raw = output[:, 2]

            # Apply same scaling as in training
            p_scaled = p_raw  # or your pressure scaling
            Cp = 2 * p_scaled.cpu().numpy()  # Cp = 2*p for this normalization

        plt.figure(figsize=(12, 6))
        plt.plot(x_surf, Cp, 'bo-', linewidth=2, markersize=3)
        plt.xlabel('x/c')
        plt.ylabel('Cp')
        plt.title('Surface Pressure Coefficient')
        plt.grid(True, alpha=0.3)
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.savefig(f"{save_dir}/surface_pressure.png", dpi=200, bbox_inches='tight')
        plt.close()

        # 5. Wake profile
        print("Creating wake profile...")
        x_wake = 5.0
        y_wake = np.linspace(-2, 2, 100)

        x_tensor = torch.tensor(np.full_like(y_wake, x_wake), dtype=torch.float32, device=device)
        y_tensor = torch.tensor(y_wake, dtype=torch.float32, device=device)

        with torch.no_grad():
            x_scaled, y_scaled = self._scale_torch(x_tensor, y_tensor)
            xy_wake = torch.stack([x_scaled, y_scaled], dim=1)
            output = self.net(xy_wake)
            u_raw = output[:, 0]
            v_raw = output[:, 1]

            # Apply same scaling as in training
            u_scaled = 1.0 + 0.5 * torch.tanh(u_raw)
            v_scaled = 0.3 * torch.tanh(v_raw)

            u_wake = u_scaled.cpu().numpy()
            v_wake = v_scaled.cpu().numpy()

        plt.figure(figsize=(8, 10))
        plt.plot(u_wake, y_wake, 'b-', linewidth=2, label='u-velocity')
        plt.plot(v_wake, y_wake, 'r-', linewidth=2, label='v-velocity')
        plt.axvline(x=1.0, color='k', linestyle='--', alpha=0.5)
        plt.xlabel('Velocity')
        plt.ylabel('y/c')
        plt.title(f'Wake Profile at x = {x_wake}c')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f"{save_dir}/wake_profile.png", dpi=200, bbox_inches='tight')
        plt.close()

        print(f"All visualizations saved to {save_dir}/")

    def generate_report(self, forces, train_time, save_dir="results"):
        """Generate final report"""
        report_path = f"{save_dir}/PINN_Analysis_Report.txt"

        with open(report_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("PINN FLOW ANALYSIS - NACA 0012 AIRFOIL\n")
            f.write("=" * 80 + "\n\n")

            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Device: {device} ({torch.cuda.get_device_name() if device.type == 'cuda' else 'CPU'})\n\n")

            f.write("PROBLEM SETUP\n")
            f.write("-" * 40 + "\n")
            f.write(f"Airfoil: NACA 0012\n")
            f.write(f"Reynolds Number: {self.Re}\n")
            f.write(f"Angle of Attack: 0°\n")
            f.write(f"Domain: x ∈ [-5,15], y ∈ [-5,5]\n\n")

            f.write("RESULTS\n")
            f.write("-" * 40 + "\n")
            f.write(f"Training Time: {train_time:.1f} seconds\n\n")

            f.write(f"FORCE COEFFICIENTS\n")
            f.write(f"CL (total):     {forces['CL_total']:8.6f}\n")
            f.write(f"CL (pressure):  {forces['CL_pressure']:8.6f}\n")
            f.write(f"CL (viscous):   {forces['CL_viscous']:8.6f}\n\n")

            f.write(f"CD (total):     {forces['CD_total']:8.6f}\n")
            f.write(f"CD (pressure):  {forces['CD_pressure']:8.6f}\n")
            f.write(f"CD (viscous):   {forces['CD_viscous']:8.6f}\n\n")

            f.write("FILES GENERATED\n")
            f.write("-" * 40 + "\n")
            f.write("• velocity_magnitude.png\n")
            f.write("• pressure_contours.png\n")
            f.write("• streamlines.png\n")
            f.write("• surface_pressure.png\n")
            f.write("• wake_profile.png\n")
            f.write("• flow_field_data.npz\n")
            f.write("• trained_model.pth\n")
            f.write("=" * 80 + "\n")

        print(f"Report saved: {report_path}")


def main():
    """Optimized main execution"""
    print("OPTIMIZED PINN FOR NACA 0012 AIRFOIL")
    print("=" * 50)

    # Initialize solver
    solver = NavierStokesPINN(Re=200)

    # Train model
    loss_history, train_time = solver.train(epochs=15000, print_freq=300)

    # Create grid and predict
    print("\nGenerating results...")
    x = np.linspace(-5, 15, 200)
    y = np.linspace(-5, 5, 100)
    X, Y = np.meshgrid(x, y)
    mask = solver.airfoil.is_inside_airfoil_vectorized(X, Y)

    U, V, P = solver.predict_field_batch(X, Y, mask)
    forces = solver.compute_forces_fast()

    # Display results
    print("\n" + "=" * 50)
    print("RESULTS SUMMARY")
    print("=" * 50)
    print(f"Training Time: {train_time:.1f} seconds")
    print(f"Final Loss: {loss_history[-1]:.2e}")
    print(f"\nForce Coefficients:")
    print(f"  CL (total):     {forces['CL_total']:8.6f}")
    print(f"  CL (pressure):  {forces['CL_pressure']:8.6f}")
    print(f"  CL (viscous):   {forces['CL_viscous']:8.6f}")
    print(f"  CD (total):     {forces['CD_total']:8.6f}")
    print(f"  CD (pressure):  {forces['CD_pressure']:8.6f}")
    print(f"  CD (viscous):   {forces['CD_viscous']:8.6f}")

    # Save results
    save_dir = "PINN_NACA0012_Results"
    os.makedirs(save_dir, exist_ok=True)

    # Save data and model
    print(f"\nSaving results to {save_dir}/...")
    np.savez(f"{save_dir}/flow_field_data.npz",
             X=X, Y=Y, U=U, V=V, P=P, mask=mask)
    # Save model as CPU copy to avoid pinned GPU memory
    model_state = {k: v.cpu() for k, v in solver.net.state_dict().items()}
    torch.save(model_state, f"{save_dir}/trained_model.pth")

    # Create visualizations
    solver.create_visualizations(X, Y, U, V, P, mask, forces, save_dir)

    # Generate report
    solver.generate_report(forces, train_time, save_dir)

    print(f"\n✅ Analysis complete! All files saved to '{save_dir}/'")
    print(f"📊 Check the visualizations and report for detailed results.")

    # Memory cleanup
    if device.type == 'cuda':
        torch.cuda.empty_cache()
        print(f"🔧 GPU memory released")


if __name__ == "__main__":
    main()
